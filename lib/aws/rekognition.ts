// AWS Rekognition integration for SevisPass
// This file handles facial recognition, liveness detection, and face comparison

import {
  RekognitionClient,
  DetectFacesCommand,
  CompareFacesCommand,
  CreateCollectionCommand,
  IndexFacesCommand,
  SearchFacesByImageCommand,
  DeleteFacesCommand,
  ListCollectionsCommand,
  DetectTextCommand,
  type Face,
  type ComparedFace,
  type FaceMatch
} from '@aws-sdk/client-rekognition';
import {
  RekognitionStreamingClient,
  StartFaceLivenessSessionCommand,
} from '@aws-sdk/client-rekognitionstreaming';
import { Amplify } from 'aws-amplify';
import { fetchAuthSession } from 'aws-amplify/auth';
import { fetchAuthSession as fetchAuthSessionServer } from 'aws-amplify/auth/server';
import outputs from '@/amplify_outputs.json';

// Get AWS credentials from Amplify (client-side)
async function getAmplifyCredentials() {
  try {
    // Ensure Amplify is configured
    const config = Amplify.getConfig();
    if (!config.Auth?.Cognito?.userPoolId) {
      console.log('Amplify not configured, configuring now...');
      Amplify.configure(outputs);
    }

    const session = await fetchAuthSession();

    if (!session.credentials) {
      throw new Error('No AWS credentials available');
    }

    return {
      region: config.Auth?.Cognito?.userPoolId ?
        config.Auth.Cognito.userPoolId.split('_')[0] : 'ap-southeast-2',
      credentials: {
        accessKeyId: session.credentials.accessKeyId,
        secretAccessKey: session.credentials.secretAccessKey,
        sessionToken: session.credentials.sessionToken,
      }
    };
  } catch (error) {
    console.error('Error getting Amplify credentials:', error);
    throw error;
  }
}

// Get AWS credentials from Amplify (server-side with context)
async function getAmplifyCredentialsServer(contextSpec?: any) {
  try {
    // Ensure Amplify is configured
    const config = Amplify.getConfig();
    if (!config.Auth?.Cognito?.userPoolId) {
      console.log('Amplify not configured, configuring now...');
      Amplify.configure(outputs);
    }

    console.log('Fetching auth session with context:', !!contextSpec);

    // Get session - this should work for both authenticated and unauthenticated users
    // Force refresh to ensure we get the latest IAM permissions
    const session = contextSpec
      ? await fetchAuthSessionServer(contextSpec, { forceRefresh: true })
      : await fetchAuthSession({ forceRefresh: true });

    console.log('Auth session result:', {
      hasCredentials: !!session.credentials,
      hasAccessKey: !!session.credentials?.accessKeyId,
      hasSecretKey: !!session.credentials?.secretAccessKey,
      hasSessionToken: !!session.credentials?.sessionToken,
      identityId: session.identityId,
      // Check if this is authenticated or unauthenticated
      isAuthenticated: session.identityId && !session.identityId.includes('unauthenticated')
    });

    // Log the actual role being used for debugging
    if (session.credentials?.sessionToken) {
      console.log('Session token preview:', session.credentials.sessionToken.substring(0, 50) + '...');
    }

    if (!session.credentials) {
      throw new Error('No AWS credentials available. Make sure Amplify backend is deployed with proper IAM permissions.');
    }

    return {
      region: outputs.auth.aws_region || 'ap-southeast-2',
      credentials: {
        accessKeyId: session.credentials.accessKeyId,
        secretAccessKey: session.credentials.secretAccessKey,
        sessionToken: session.credentials.sessionToken,
      }
    };
  } catch (error) {
    console.error('Error getting Amplify credentials:', error);
    console.error('Make sure to run "npx ampx sandbox" to deploy your backend');
    throw error;
  }
}

// Initialize Rekognition client with Amplify credentials
async function getRekognitionClient(contextSpec?: any): Promise<RekognitionClient> {
  const { region, credentials } = contextSpec
    ? await getAmplifyCredentialsServer(contextSpec)
    : await getAmplifyCredentials();

  return new RekognitionClient({
    region,
    credentials,
  });
}

// Initialize Rekognition Streaming client for Face Liveness
async function getRekognitionStreamingClient(contextSpec?: any): Promise<RekognitionStreamingClient> {
  const { region, credentials } = contextSpec
    ? await getAmplifyCredentialsServer(contextSpec)
    : await getAmplifyCredentials();

  return new RekognitionStreamingClient({
    region,
    credentials,
  });
}

// Collection name for storing SevisPass face vectors
const SEVISPASS_COLLECTION = 'sevispass-faces';

/**
 * Helper function to reconstruct fragmented MRZ lines
 */
function reconstructMRZLines(mrzCandidates: Array<{text: string; confidence: number}>): string[] {
  const reconstructed: string[] = [];
  
  // Group candidates by common MRZ patterns
  const line1Candidates = mrzCandidates.filter(c => 
    /P[<\s]*PNG/i.test(c.text) || c.text.includes('<<')
  );
  
  const line2Candidates = mrzCandidates.filter(c => 
    /[A-Z0-9]{8,}/.test(c.text) && c.text.includes('PNG') && !c.text.includes('P<PNG')
  );
  
  // Attempt to reconstruct MRZ line 1 (name line)
  if (line1Candidates.length > 0) {
    // Find the best line 1 candidate or combine fragments
    let bestLine1 = line1Candidates[0].text;
    
    // If we have multiple candidates, try to combine them intelligently
    if (line1Candidates.length > 1) {
      const fragments = line1Candidates.map(c => c.text).join(' ');
      // Clean up and standardize
      const cleaned = fragments
        .replace(/\s+/g, '')  // Remove spaces
        .replace(/[^A-Z<]/g, '') // Keep only letters and <
        .toUpperCase();
      
      if (cleaned.length > bestLine1.replace(/[^A-Z<]/g, '').length) {
        bestLine1 = cleaned;
      }
    }
    
    // Standardize the format
    if (bestLine1 && bestLine1.length > 10) {
      bestLine1 = bestLine1.replace(/\s+/g, '').toUpperCase();
      // Ensure proper P<PNG format
      if (!bestLine1.startsWith('P<PNG')) {
        if (bestLine1.includes('PNG')) {
          bestLine1 = bestLine1.replace(/.*PNG/, 'P<PNG');
        }
      }
      reconstructed.push(bestLine1);
    }
  }
  
  // Attempt to reconstruct MRZ line 2 (document info)
  if (line2Candidates.length > 0) {
    let bestLine2 = line2Candidates[0].text;
    
    // Clean up line 2
    if (bestLine2 && bestLine2.length > 15) {
      bestLine2 = bestLine2.replace(/\s+/g, '').toUpperCase();
      reconstructed.push(bestLine2);
    }
  }
  
  return reconstructed.filter(line => line.length > 10);
}

// Confidence thresholds - Lowered for maximum accessibility
export const CONFIDENCE_THRESHOLDS = {
  AUTO_APPROVE: 50,  // Lowered from 70% to 50% - instant approval
  MANUAL_REVIEW: 30, // Lowered from 50% to 30% - wider manual review range
  REJECT: 30,        // Lowered from 50% to 30% - more lenient rejection
  LOGIN: 50,         // Lowered from 60% to 50% - easier facial login
} as const;

/**
 * Initialize SevisPass face collection
 */
export async function initializeCollection(contextSpec?: any): Promise<boolean> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);

    // Check if collection already exists
    const listCommand = new ListCollectionsCommand({});
    const collections = await rekognitionClient.send(listCommand);

    if (collections.CollectionIds?.includes(SEVISPASS_COLLECTION)) {
      console.log('SevisPass collection already exists');
      return true;
    }

    // Create new collection
    const createCommand = new CreateCollectionCommand({
      CollectionId: SEVISPASS_COLLECTION,
    });

    await rekognitionClient.send(createCommand);
    console.log('SevisPass collection created successfully');
    return true;
  } catch (error) {
    console.error('Error initializing collection:', error);
    return false;
  }
}

/**
 * Detect faces in an image and check quality
 */
export async function detectFaces(imageBytes: Uint8Array, contextSpec?: any): Promise<{
  faces: Face[];
  isGoodQuality: boolean;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);
    const command = new DetectFacesCommand({
      Image: { Bytes: imageBytes },
      Attributes: ['ALL'],
    });

    const response = await rekognitionClient.send(command);
    const faces = response.FaceDetails || [];

    if (faces.length === 0) {
      return {
        faces: [],
        isGoodQuality: false,
        error: 'No face detected in image'
      };
    }

    if (faces.length > 1) {
      return {
        faces,
        isGoodQuality: false,
        error: 'Multiple faces detected. Please ensure only one person is in the image'
      };
    }

    const face = faces[0];

    // Check face quality requirements - Relaxed for better accessibility
    const quality = face.Quality;
    const isGoodQuality =
      (quality?.Brightness || 0) >= 10 &&  // Lowered from 20 - accept darker images
      (quality?.Brightness || 0) <= 90 &&  // Raised from 80 - accept brighter images
      (quality?.Sharpness || 0) >= 10 &&   // Lowered from 20 - accept slightly blurry images
      (face.Confidence || 0) >= 70;        // Lowered from 90 - more lenient face detection

    if (!isGoodQuality) {
      console.log('Face quality check failed:', {
        brightness: quality?.Brightness || 0,
        sharpness: quality?.Sharpness || 0,
        confidence: face.Confidence || 0,
        requirements: { minBrightness: 10, maxBrightness: 90, minSharpness: 10, minConfidence: 70 }
      });
    }

    return {
      faces,
      isGoodQuality,
      error: isGoodQuality ? undefined : `Image quality insufficient. Brightness: ${quality?.Brightness || 0}, Sharpness: ${quality?.Sharpness || 0}, Face Confidence: ${face.Confidence || 0}`
    };
  } catch (error) {
    console.error('Error detecting faces:', error);
    return {
      faces: [],
      isGoodQuality: false,
      error: 'Failed to analyze image'
    };
  }
}

/**
 * Compare two face images
 */
export async function compareFaces(
  sourceImageBytes: Uint8Array,
  targetImageBytes: Uint8Array,
  contextSpec?: any
): Promise<{
  similarity: number;
  isMatch: boolean;
  confidence: number;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);
    const command = new CompareFacesCommand({
      SourceImage: { Bytes: sourceImageBytes },
      TargetImage: { Bytes: targetImageBytes },
      SimilarityThreshold: 30, // Minimum threshold for comparison - lowered to 30% for maximum accessibility
    });

    const response = await rekognitionClient.send(command);

    if (!response.FaceMatches || response.FaceMatches.length === 0) {
      return {
        similarity: 0,
        isMatch: false,
        confidence: 0,
        error: 'No face match found'
      };
    }

    const match = response.FaceMatches[0];
    const similarity = match.Similarity || 0;
    const confidence = match.Face?.Confidence || 0;

    return {
      similarity,
      isMatch: similarity >= CONFIDENCE_THRESHOLDS.REJECT,
      confidence,
    };
  } catch (error) {
    console.error('Error comparing faces:', error);
    return {
      similarity: 0,
      isMatch: false,
      confidence: 0,
      error: 'Failed to compare faces'
    };
  }
}

/**
 * Index a face in the SevisPass collection
 */
export async function indexFace(
  imageBytes: Uint8Array,
  externalImageId: string, // UIN
  maxFaces: number = 1,
  contextSpec?: any
): Promise<{
  faceId?: string;
  success: boolean;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);
    const command = new IndexFacesCommand({
      CollectionId: SEVISPASS_COLLECTION,
      Image: { Bytes: imageBytes },
      ExternalImageId: externalImageId,
      MaxFaces: maxFaces,
      QualityFilter: 'AUTO',
      DetectionAttributes: ['ALL'],
    });

    const response = await rekognitionClient.send(command);

    if (!response.FaceRecords || response.FaceRecords.length === 0) {
      return {
        success: false,
        error: 'No suitable face found for indexing'
      };
    }

    const faceRecord = response.FaceRecords[0];
    return {
      faceId: faceRecord.Face?.FaceId,
      success: true,
    };
  } catch (error) {
    console.error('Error indexing face:', error);
    return {
      success: false,
      error: 'Failed to index face in collection'
    };
  }
}

/**
 * Search for a face in the collection
 */
export async function searchFaceInCollection(
  imageBytes: Uint8Array,
  threshold: number = CONFIDENCE_THRESHOLDS.LOGIN
): Promise<{
  matches: FaceMatch[];
  bestMatch?: {
    uin: string;
    confidence: number;
  };
  success: boolean;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient();
    const command = new SearchFacesByImageCommand({
      CollectionId: SEVISPASS_COLLECTION,
      Image: { Bytes: imageBytes },
      FaceMatchThreshold: threshold,
      MaxFaces: 5,
    });

    const response = await rekognitionClient.send(command);
    const matches = response.FaceMatches || [];

    if (matches.length === 0) {
      return {
        matches: [],
        success: false,
        error: 'No matching face found in collection'
      };
    }

    // Get the best match
    const bestMatch = matches[0];
    const uin = bestMatch.Face?.ExternalImageId;
    const confidence = bestMatch.Similarity || 0;

    return {
      matches,
      bestMatch: uin ? { uin, confidence } : undefined,
      success: true,
    };
  } catch (error) {
    console.error('Error searching face in collection:', error);
    return {
      matches: [],
      success: false,
      error: 'Failed to search face in collection'
    };
  }
}

/**
 * Remove a face from the collection
 */
export async function removeFaceFromCollection(faceId: string): Promise<boolean> {
  try {
    const rekognitionClient = await getRekognitionClient();
    const command = new DeleteFacesCommand({
      CollectionId: SEVISPASS_COLLECTION,
      FaceIds: [faceId],
    });

    await rekognitionClient.send(command);
    return true;
  } catch (error) {
    console.error('Error removing face from collection:', error);
    return false;
  }
}

/**
 * Detect text in images (wrapper for API compatibility)
 */
export async function detectText(imageBytes: Buffer, contextSpec?: any): Promise<any[]> {
  try {
    const uint8Array = new Uint8Array(imageBytes);
    const result = await extractTextFromDocument(uint8Array, contextSpec);
    return result.detectedText;
  } catch (error) {
    console.error('Error in detectText wrapper:', error);
    return [];
  }
}

/**
 * Extract text from identity documents
 */
export async function extractTextFromDocument(
  imageBytes: Uint8Array,
  contextSpec?: any
): Promise<{
  text: string;
  detectedText: any[];
  success: boolean;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);
    const command = new DetectTextCommand({
      Image: { Bytes: imageBytes },
    });

    const response = await rekognitionClient.send(command);
    const textDetections = response.TextDetections || [];

    // Extract all detected text
    const extractedText = textDetections
      .filter(detection => detection.Type === 'LINE')
      .map(detection => detection.DetectedText || '')
      .join('\n');

    return {
      text: extractedText,
      detectedText: textDetections,
      success: true,
    };
  } catch (error) {
    console.error('Error extracting text from document:', error);
    return {
      text: '',
      detectedText: [],
      success: false,
      error: 'Failed to extract text from document'
    };
  }
}

/**
 * Analyze identity documents using Rekognition DetectText with intelligent parsing
 * Enhanced text extraction and parsing specifically for PNG identity documents
 */
export async function analyzeIdentityDocument(
  imageBytes: Uint8Array,
  documentType?: string,
  contextSpec?: any
): Promise<{
  extractedData: {
    firstName?: string;
    lastName?: string;
    fullName?: string;
    dateOfBirth?: string;
    documentNumber?: string;
    nationality?: string;
    documentType?: string;
  };
  success: boolean;
  error?: string;
}> {
  try {
    const rekognitionClient = await getRekognitionClient(contextSpec);
    
    // Enhanced text detection settings optimized for passport MRZ zone
    console.log('üîç Rekognition: Starting enhanced text detection optimized for MRZ zone...');
    const command = new DetectTextCommand({
      Image: { Bytes: imageBytes },
      Filters: {
        WordFilter: {
          MinConfidence: 30, // Even lower confidence for MRZ text which can be small/faint
          MinBoundingBoxHeight: 0.003, // Very small minimum box to capture MRZ text
          MinBoundingBoxWidth: 0.003
        },
        RegionsOfInterest: [
          {
            // Focus on bottom 30% of image where MRZ typically appears
            BoundingBox: {
              Width: 1.0,  // Full width
              Height: 0.3, // Bottom 30% of image
              Left: 0.0,
              Top: 0.7     // Start from 70% down the image
            }
          },
          {
            // Also scan the full image as backup
            BoundingBox: {
              Width: 1.0,
              Height: 1.0,
              Left: 0.0,
              Top: 0.0
            }
          }
        ]
      }
    });

    const response = await rekognitionClient.send(command);
    const textDetections = response.TextDetections || [];

    // Extract all detected text with better filtering
    const lineDetections = textDetections
      .filter(detection => detection.Type === 'LINE' && detection.DetectedText)
      .map(detection => ({
        text: detection.DetectedText!,
        confidence: detection.Confidence || 0
      }))
      .sort((a, b) => b.confidence - a.confidence); // Sort by confidence

    const wordDetections = textDetections
      .filter(detection => detection.Type === 'WORD' && detection.DetectedText)
      .map(detection => ({
        text: detection.DetectedText!,
        confidence: detection.Confidence || 0
      }));

    let allText = lineDetections.map(d => d.text).join('\n');
    const allWords = wordDetections.map(d => d.text).join(' ');

    console.log('üìÑ Rekognition detected lines:', lineDetections.length);
    console.log('üìÑ Rekognition detected words:', wordDetections.length);
    console.log('üìù Full text extracted:\n', allText);
    console.log('üî§ All words:', allWords);

    // Pre-process text to find potential MRZ lines
    console.log('üîç Pre-processing text to identify MRZ patterns...');
    const mrzCandidateLines = lineDetections
      .filter(detection => {
        const text = detection.text;
        // Look for lines that contain typical MRZ characteristics
        return (
          text.includes('PNG') || 
          text.includes('P<PNG') ||
          /P[<\s]*PNG/i.test(text) ||
          text.includes('<<') || 
          /[A-Z]{2,}[<]{2,}[A-Z]{2,}/i.test(text) || // Names with << separators
          /^[A-Z0-9<]{20,}$/i.test(text.replace(/\s/g, '')) // Long alphanumeric strings typical of MRZ
        );
      })
      .sort((a, b) => b.confidence - a.confidence);

    if (mrzCandidateLines.length > 0) {
      console.log('üéØ Found MRZ candidate lines:', mrzCandidateLines.map(l => l.text));
      
      // Create a focused MRZ text for parsing
      const mrzFocusedText = mrzCandidateLines.map(l => l.text).join('\n');
      console.log('üéØ MRZ-focused text for parsing:\n', mrzFocusedText);
      
      // Use this focused text for MRZ parsing in addition to full text
      allText = allText + '\n' + mrzFocusedText;
      
      // Try to reconstruct fragmented MRZ lines
      console.log('üîß Attempting MRZ line reconstruction...');
      const reconstructedMRZ = reconstructMRZLines(mrzCandidateLines);
      if (reconstructedMRZ.length > 0) {
        console.log('üîß Reconstructed MRZ lines:', reconstructedMRZ);
        allText = allText + '\n' + reconstructedMRZ.join('\n');
      }
    }

    if (!allText) {
      return {
        extractedData: {},
        success: false,
        error: 'No text detected in document'
      };
    }

    // Enhanced parsing for different PNG document types
    console.log(`üîç Starting document analysis for type: ${documentType || 'unknown'}...`);
    
    let mrzPatterns: RegExp[] = [];
    const extractedData: any = {
      nationality: 'Papua New Guinea' // Default for PNG documents
    };
    
    // Define patterns based on document type
    if (documentType === 'png_passport' || documentType?.includes('passport') || !documentType) {
      console.log('üîç Using PNG Passport MRZ patterns...');
      // PNG Passport MRZ format: P<PNGLASTNAME<<FIRSTNAME<MIDDLENAME<<<<<
      //                         YYMMDDXNNNNNNNN9PNG9999999M2209304<<<<<<<<<<1
      mrzPatterns = [
        // Exact PNG passport MRZ format: P<PNGBIRIBUDO<<JESSE<TUKAU
        /P<PNG([A-Z]+)<<([A-Z]+)<([A-Z]+)/i,
        // Standard format with flexible separators: P<PNGLASTNAME<<FIRSTNAME<MIDDLENAME<<<<<
        /P<PNG([A-Z][A-Z]*?)(<+)([A-Z][A-Z]*?)(<*)([A-Z][A-Z]*?)?(<*)/i,
        // Alternative format with spaces: P PNG LASTNAME << FIRSTNAME
        /P[<\s]PNG[<\s]+([A-Z]+)[<\s]+([A-Z]+)[<\s]*([A-Z]*)/i,
        // Relaxed format allowing for OCR errors: P PNG or PPNG
        /(P[<\s]*PNG|PPNG)[<\s]+([A-Z][A-Z]*?)[<\s]*([A-Z][A-Z]*?)[<\s]*([A-Z][A-Z]*?)?/i
      ];
      extractedData.documentType = 'Passport';
      
    } else if (documentType === 'nid') {
      console.log('üîç Using PNG National ID patterns...');
      // PNG National ID patterns - typically printed names
      mrzPatterns = [
        // Look for structured name fields on NID
        /(?:NAME|FULL\s*NAME|GIVEN\s*NAME)[:\s]+([A-Z\s]+)/i,
        // Alternative: SURNAME, GIVEN NAME format
        /(?:SURNAME)[:\s]+([A-Z]+)[,\s]+(?:GIVEN\s*NAME)[:\s]+([A-Z\s]+)/i,
        // Simple pattern: LASTNAME, FIRSTNAME format
        /([A-Z]{2,}),\s*([A-Z]{2,}(?:\s+[A-Z]+)*)/i
      ];
      extractedData.documentType = 'National ID';
      
    } else if (documentType === 'drivers_license') {
      console.log('üîç Using PNG Driver\'s License patterns...');
      // PNG Driver's License patterns
      mrzPatterns = [
        // Driver's License name format
        /(?:NAME|FULL\s*NAME)[:\s]+([A-Z\s]+)/i,
        // License number with name nearby
        /(?:LIC(?:ENSE)?\s*(?:NO|NUMBER)?)[:\s]+([A-Z0-9]+)[\s\S]*?([A-Z]{2,}\s+[A-Z\s]*)/i,
        // Standard name format
        /([A-Z]{2,})\s+([A-Z]{2,}(?:\s+[A-Z]+)*)/i
      ];
      extractedData.documentType = 'Driver\'s License';
      
    } else {
      console.log('üîç Using generic PNG document patterns...');
      // Generic patterns for unknown document types
      mrzPatterns = [
        // Try passport patterns first
        /P<PNG([A-Z]+)<<([A-Z]+)<([A-Z]+)/i,
        // Then generic name patterns
        /(?:NAME|FULL\s*NAME)[:\s]+([A-Z\s]+)/i,
        /([A-Z]{2,})\s+([A-Z]{2,}(?:\s+[A-Z]+)*)/i
      ];
      extractedData.documentType = 'Identity Document';
    }

    let mrzFound = false;
    
    for (let i = 0; i < mrzPatterns.length && !mrzFound; i++) {
      const pattern = mrzPatterns[i];
      console.log(`Trying MRZ pattern ${i + 1}:`, pattern.source);
      
      const mrzMatch = allText.match(pattern);
      if (mrzMatch) {
        console.log('MRZ match found:', mrzMatch);
        
        let lastName, firstName, middleName, fullName;
        
        if (documentType === 'png_passport' || documentType?.includes('passport') || !documentType) {
          // Passport parsing logic
          if (i === 0) {
            // Exact PNG MRZ format: P<PNGBIRIBUDO<<JESSE<TUKAU
            lastName = mrzMatch[1]?.replace(/<+/g, '').trim();
            firstName = mrzMatch[2]?.replace(/<+/g, '').trim();
            middleName = mrzMatch[3]?.replace(/<+/g, '').trim();
          } else if (i === 1) {
            // Standard format with flexible separators
            lastName = mrzMatch[1]?.replace(/<+/g, '').trim();
            firstName = mrzMatch[3]?.replace(/<+/g, '').trim();
            middleName = mrzMatch[5]?.replace(/<+/g, '').trim();
          } else {
            // Alternative formats
            lastName = mrzMatch[1]?.replace(/[<\s]+/g, '').trim();
            firstName = mrzMatch[2]?.replace(/[<\s]+/g, '').trim();
            middleName = mrzMatch[3]?.replace(/[<\s]+/g, '').trim();
          }
          
        } else if (documentType === 'nid' || documentType === 'drivers_license') {
          // NID and Driver's License parsing logic
          if (i === 0) {
            // Full name field: "NAME: JOHN SMITH DOE"
            fullName = mrzMatch[1]?.trim();
          } else if (i === 1) {
            // SURNAME, GIVEN NAME format
            lastName = mrzMatch[1]?.trim();
            fullName = mrzMatch[2]?.trim(); // This contains first + middle names
          } else {
            // Simple LASTNAME, FIRSTNAME format
            lastName = mrzMatch[1]?.trim();
            fullName = mrzMatch[2]?.trim();
          }
          
          // Parse full name into parts if we have it
          if (fullName && !firstName) {
            const nameParts = fullName.split(/\s+/);
            if (nameParts.length >= 2) {
              firstName = nameParts[0];
              middleName = nameParts.slice(1).join(' ');
            } else {
              firstName = fullName;
            }
          }
        }

        // Validate extracted names
        if (lastName && firstName && lastName.length > 1 && firstName.length > 1) {
          // Clean up any remaining OCR artifacts
          lastName = lastName.replace(/[^A-Z]/g, '');
          firstName = firstName.replace(/[^A-Z]/g, '');
          if (middleName) {
            middleName = middleName.replace(/[^A-Z]/g, '');
          }
          
          // Additional validation - names should be reasonable length
          if (lastName.length >= 2 && firstName.length >= 2 && 
              lastName.length <= 20 && firstName.length <= 20) {
            
            extractedData.lastName = lastName;
            extractedData.firstName = firstName;
            if (middleName && middleName.length >= 2) {
              extractedData.middleName = middleName;
              extractedData.fullName = `${firstName} ${middleName} ${lastName}`;
            } else {
              extractedData.fullName = `${firstName} ${lastName}`;
            }

            extractedData.nationality = 'Papua New Guinea';
            extractedData.documentType = 'Passport';
            
            console.log('‚úÖ MRZ parsing successful with pattern', i + 1, ':', {
              lastName,
              firstName,
              middleName,
              fullName: extractedData.fullName
            });
            
            mrzFound = true;
          }
        }
      }
    }
    
    // First try to extract document number from explicit "DOCUMENT No." text
    if (!extractedData.documentNumber) {
      const docNoPattern = /DOCUMENT\s+No\.\s*([A-Z]{1,2}[0-9]{5,8})/i;
      const docNoMatch = allText.match(docNoPattern);
      if (docNoMatch) {
        extractedData.documentNumber = docNoMatch[1];
        console.log('‚úÖ Document number found from "DOCUMENT No." text:', extractedData.documentNumber);
      }
    }

    // Additional MRZ line parsing for document number and dates
    if (mrzFound || allText.includes('PNG')) {
      console.log('üîç Looking for MRZ second line (document number, dates)...');
      
      // Look for the second MRZ line with document number
      // Format: PASSPORT_NUMBER<PNG<YYMMDD<M<YYMMDD<PERSONAL_NUMBER<CHECK
      // PNG passport format: OP17999<<2PNG8110099M2612236<<
      const mrzLine2Patterns = [
        /^(O[A-Z][0-9]{5,7})[<\s]*[0-9]*PNG/im, // PNG format: OP17999
        /^([A-Z]{2}[0-9]{5,7})[<\s]*[0-9]*PNG/im, // Standard format: AB123456
        /^([A-Z0-9]{6,9})[<\s]*PNG/im, // More flexible format
      ];
      
      for (const pattern of mrzLine2Patterns) {
        const match = allText.match(pattern);
        if (match) {
          console.log('üîç MRZ Line 2 match found:', match);
          
          // Extract document number (first capture group)
          if (match[1] && !extractedData.documentNumber) {
            const docNum = match[1].replace(/[<]/g, ''); // Remove padding characters
            
            // Validate document number format
            if (/^[A-Z]{1,2}[0-9]{5,8}$/.test(docNum)) {
              extractedData.documentNumber = docNum;
              console.log('‚úÖ Document number from MRZ:', extractedData.documentNumber);
            }
          }
          
          // Extract date of birth (second capture group - first date)
          if (match[2] && match[2].length === 6 && !extractedData.dateOfBirth) {
            const dateStr = match[2];
            const year = '20' + dateStr.substring(0, 2);
            const month = dateStr.substring(2, 4);
            const day = dateStr.substring(4, 6);
            
            if (month >= '01' && month <= '12' && day >= '01' && day <= '31') {
              extractedData.dateOfBirth = `${day}/${month}/${year}`;
              console.log('‚úÖ Date of birth from MRZ:', extractedData.dateOfBirth);
            }
          }
          
          // Extract expiry date (third capture group - second date)
          if (match[3] && match[3].length === 6) {
            const expDateStr = match[3];
            const expYear = '20' + expDateStr.substring(0, 2);
            const expMonth = expDateStr.substring(2, 4);
            const expDay = expDateStr.substring(4, 6);
            console.log('‚ÑπÔ∏è Document expires:', `${expDay}/${expMonth}/${expYear}`);
          }
          break;
        }
      }
      
      // Try to extract DOB from MRZ second line (different position)
      // Format: 0P17999<<2PNG8110099M2612236<<
      // The 811009 part is YYMMDD for birth date (81-10-09 = 1981-10-09)
      const dobMatch = allText.match(/([0-9]{6})[0-9M][0-9]{6}/);
      if (dobMatch && !extractedData.dateOfBirth) {
        const dobStr = dobMatch[1];
        // Parse YYMMDD format
        let year = parseInt(dobStr.substring(0, 2));
        const month = dobStr.substring(2, 4);
        const day = dobStr.substring(4, 6);
        
        // Convert YY to full year (assume 1900s for years > 50, 2000s for <= 50)
        year = year > 50 ? 1900 + year : 2000 + year;
        
        if (month >= '01' && month <= '12' && day >= '01' && day <= '31') {
          extractedData.dateOfBirth = `${year}-${month}-${day}`;
          console.log('üìÖ Extracted DOB from MRZ:', extractedData.dateOfBirth);
        }
      }
    }

    // If MRZ parsing failed, try other name extraction methods
    if (!extractedData.fullName) {
      console.log('üîç MRZ parsing failed, trying alternative name extraction methods...');
      
      // Strategy 1: Look for "Name:" or "Given Names:" patterns
      const nameFieldPatterns = [
        /Name[:\s]+([A-Z][A-Z\s]+)/i,
        /Given\s+Names?[:\s]+([A-Z][A-Z\s]+)/i,
        /Surname[:\s]+([A-Z][A-Z\s]+)/i,
        /Family\s+Name[:\s]+([A-Z][A-Z\s]+)/i
      ];
      
      for (const pattern of nameFieldPatterns) {
        const match = allText.match(pattern);
        if (match) {
          const extractedName = match[1].trim();
          if (extractedName.length > 2) {
            extractedData.fullName = extractedName;
            console.log('‚úÖ Found name with field pattern:', extractedName);
            break;
          }
        }
      }
      
      // Strategy 2: Look for capitalized name patterns (common in passports)
      if (!extractedData.fullName) {
        // Look for lines with multiple capitalized words (likely names)
        const namePatterns = [
        /(?:Full\s*)?Name[:\s]+([A-Z][A-Za-z]+(?:\s+[A-Z][A-Za-z]+)+)/i,
        /Given\s*Name[:\s]+([A-Z][A-Za-z]+)[\s\n]+(?:Family\s*Name|Surname)[:\s]+([A-Z][A-Za-z]+)/i,
        /^([A-Z][A-Z]+)\s+([A-Z][A-Z]+)(?:\s+([A-Z][A-Z]+))?\s*$/m, // All caps names on separate line
      ];

      for (const pattern of namePatterns) {
        const match = allText.match(pattern);
        if (match) {
          if (pattern.source.includes('Given')) {
            // Given name + surname pattern
            extractedData.firstName = match[1].trim();
            extractedData.lastName = match[2].trim();
            extractedData.fullName = `${extractedData.firstName} ${extractedData.lastName}`;
          } else if (match.length === 4) {
            // All caps names pattern (firstName lastName middleName)
            const firstName = match[1].trim();
            const lastName = match[2].trim();
            const middleName = match[3] ? match[3].trim() : '';
            
            // Validate names don't contain document keywords
            const invalidKeywords = ['TYPE', 'PASSPORT', 'DOCUMENT', 'PNG', 'REPUBLIC'];
            const isValidName = ![firstName, lastName, middleName].some(name => 
              name && invalidKeywords.some(keyword => name.includes(keyword))
            );
            
            if (isValidName && firstName.length > 1 && lastName.length > 1) {
              extractedData.firstName = firstName;
              extractedData.lastName = lastName;
              if (middleName) extractedData.middleName = middleName;
              
              extractedData.fullName = middleName
                ? `${firstName} ${middleName} ${lastName}`
                : `${firstName} ${lastName}`;
            }
          } else {
            // Full name pattern
            const nameValue = match[1].trim();
            const invalidKeywords = ['TYPE', 'PASSPORT', 'DOCUMENT', 'ASSEPORT', 'REPUBLIC'];
            const isValidName = !invalidKeywords.some(keyword => nameValue.includes(keyword));
            
            if (isValidName && nameValue.length > 3 && nameValue.includes(' ')) {
              extractedData.fullName = nameValue;
              // Try to split into parts
              const parts = nameValue.split(/\s+/);
              if (parts.length >= 2) {
                extractedData.firstName = parts[0];
                extractedData.lastName = parts[parts.length - 1];
              }
            }
          }

          if (extractedData.fullName) {
            console.log('Pattern matching successful:', extractedData.fullName);
            break;
          }
        }
      }
      
      // Strategy 3: Word-based analysis for name detection
      if (!extractedData.fullName && wordDetections.length > 0) {
        console.log('üî§ Trying word-based name extraction...');
        
        // Look for sequences of capitalized words that could be names
        const validNameWords = wordDetections
          .filter(w => w.confidence > 60) // Higher confidence words
          .map(w => w.text)
          .filter(word => {
            // Filter valid name words
            return /^[A-Z][a-z]+$/.test(word) && // Proper capitalization
                   word.length > 1 && 
                   !['PNG', 'PAPUA', 'GUINEA', 'REPUBLIC', 'PASSPORT', 'DOCUMENT'].includes(word.toUpperCase());
          });
        
        if (validNameWords.length >= 2) {
          // Try to find name sequences
          const potentialNames = [];
          for (let i = 0; i <= validNameWords.length - 2; i++) {
            const nameCandidate = validNameWords.slice(i, i + Math.min(3, validNameWords.length - i)).join(' ');
            if (nameCandidate.split(' ').length >= 2) {
              potentialNames.push(nameCandidate);
            }
          }
          
          if (potentialNames.length > 0) {
            // Use the longest potential name
            extractedData.fullName = potentialNames.reduce((longest, current) => 
              current.length > longest.length ? current : longest
            );
            console.log('‚úÖ Word-based extraction found:', extractedData.fullName);
            
            // Split into parts
            const parts = extractedData.fullName.split(' ');
            if (parts.length >= 2) {
              extractedData.firstName = parts[0];
              extractedData.lastName = parts[parts.length - 1];
              if (parts.length === 3) {
                extractedData.middleName = parts[1];
              }
            }
          }
        }
      }
    }
    }

    // Extract document number
    if (!extractedData.documentNumber) {
      const docPatterns = [
        /Passport\s*(?:No|Number)[:\s]+([A-Z0-9]+)/i,
        /Document\s*(?:No|Number)[:\s]+([A-Z0-9]+)/i,
        /([A-Z]{1,2}\d{6,9})/g, // PNG passport format
        /P<PNG[^<]+<<[^<]+<?[^<]*<*[\r\n]+([A-Z0-9]{8,9})/i // MRZ second line
      ];

      for (const pattern of docPatterns) {
        const match = allText.match(pattern);
        if (match) {
          extractedData.documentNumber = match[1];
          console.log('Document number found:', extractedData.documentNumber);
          break;
        }
      }
    }

    // Extract date of birth
    if (!extractedData.dateOfBirth) {
      const datePatterns = [
        /Date\s*of\s*Birth[:\s]+(\d{1,2}[-/]\d{1,2}[-/]\d{4})/i,
        /DOB[:\s]+(\d{1,2}[-/]\d{1,2}[-/]\d{4})/i,
        /Born[:\s]+(\d{1,2}[-/]\d{1,2}[-/]\d{4})/i,
        /(\d{1,2}[-/]\d{1,2}[-/]\d{4})/g
      ];

      for (const pattern of datePatterns) {
        const match = allText.match(pattern);
        if (match) {
          const dateStr = match[1];
          // Convert to YYYY-MM-DD format
          const dateParts = dateStr.split(/[-/]/);
          if (dateParts.length === 3) {
            const [day, month, year] = dateParts;
            extractedData.dateOfBirth = `${year}-${month.padStart(2, '0')}-${day.padStart(2, '0')}`;
            console.log('Date of birth found:', extractedData.dateOfBirth);
            break;
          }
        }
      }
    }

    // Set default nationality for PNG documents
    if (!extractedData.nationality && (allText.includes('PNG') || allText.includes('Papua New Guinea'))) {
      extractedData.nationality = 'Papua New Guinea';
    }

    // AGGRESSIVE FALLBACK: If still no name found, try to extract ANY reasonable text
    if (!extractedData.fullName) {
      console.log('Using aggressive fallback name extraction...');
      
      // Get all text lines and try to find name-like patterns
      const lines = allText.split('\n').map(line => line.trim()).filter(line => line.length > 0);
      
      for (const line of lines) {
        // Look for any line with 2+ words that could be a name
        const words = line.split(/\s+/).filter(word => 
          word.length > 1 && 
          /^[A-Za-z]+$/.test(word) && // Only letters
          !['TYPE', 'PASSPORT', 'DOCUMENT', 'PNG', 'REPUBLIC', 'ISSUE', 'EXPIRE', 'DATE', 'BIRTH', 'PLACE', 'OF', 'THE', 'AND', 'OR'].includes(word.toUpperCase())
        );
        
        if (words.length >= 2 && words.length <= 4) {
          // This looks like it could be a name
          extractedData.firstName = words[0];
          extractedData.lastName = words[words.length - 1];
          if (words.length > 2) {
            extractedData.middleName = words.slice(1, -1).join(' ');
          }
          
          extractedData.fullName = words.join(' ');
          console.log('Aggressive fallback found name:', extractedData.fullName);
          break;
        }
      }
    }
    
    // If no name found, leave empty - let Google AI handle it or user input provide it
    if (!extractedData.fullName) {
      console.log('No name found in document - leaving empty for AI analysis');
    }

    console.log('Rekognition ID analysis result:', extractedData);

    return {
      extractedData,
      success: Object.keys(extractedData).length > 0,
    };
  } catch (error) {
    console.error('Error analyzing identity document with Rekognition:', error);
    return {
      extractedData: {},
      success: false,
      error: 'Failed to analyze identity document'
    };
  }
}

/**
 * Start a face liveness session using AWS Rekognition Face Liveness
 */
export async function startLivenessSession(): Promise<{
  sessionId?: string;
  success: boolean;
  error?: string;
}> {
  try {
    const rekognitionStreamingClient = await getRekognitionStreamingClient();

    const command = new StartFaceLivenessSessionCommand({
      SessionId: `sevispass-${Date.now()}-${Math.random().toString(36).substring(2)}`,
      VideoWidth: "640",
      VideoHeight: "480",
      ChallengeVersions: "FaceMovementAndLightChallenge_1.0.0"
    });

    const response = await rekognitionStreamingClient.send(command);

    return {
      sessionId: response.SessionId || `live-${Date.now()}-${Math.random().toString(36).substring(2)}`,
      success: true,
    };
  } catch (error) {
    console.error('Error starting liveness session:', error);
    return {
      success: false,
      error: 'Failed to start liveness session'
    };
  }
}

/**
 * Get liveness session results
 * Note: Face Liveness results are retrieved through regular Rekognition client
 */
export async function getLivenessSessionResults(sessionId: string): Promise<{
  isLive: boolean;
  confidence: number;
  success: boolean;
  error?: string;
}> {
  try {
    // Face Liveness results are actually retrieved through a different API
    // For now, we'll simulate the liveness check based on session activity
    // In production, you'd integrate with the Face Liveness WebSocket API

    if (!sessionId || !sessionId.startsWith('live-')) {
      return {
        isLive: false,
        confidence: 0,
        success: false,
        error: 'Invalid liveness session ID'
      };
    }

    // Simulate liveness detection results
    // In production, this would poll the actual Face Liveness session status
    const mockConfidence = 90 + Math.random() * 10; // 90-100% confidence
    const isLive = mockConfidence >= 85;

    return {
      isLive,
      confidence: mockConfidence,
      success: true,
    };
  } catch (error) {
    console.error('Error getting liveness session results:', error);
    return {
      isLive: false,
      confidence: 0,
      success: false,
      error: 'Failed to get liveness session results'
    };
  }
}

/**
 * Utility function to convert base64 image to Uint8Array
 */
export function base64ToUint8Array(base64String: string): Uint8Array {
  // Remove data URL prefix if present
  const base64Data = base64String.replace(/^data:image\/[a-z]+;base64,/, '');
  const binaryString = atob(base64Data);
  const bytes = new Uint8Array(binaryString.length);

  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }

  return bytes;
}

/**
 * Comprehensive face verification for SevisPass registration
 */
export async function verifySevisPassRegistration(
  selfieBase64: string,
  documentPhotoBase64: string,
  uin: string,
  contextSpec?: any
): Promise<{
  approved: boolean;
  confidence: number;
  requiresManualReview: boolean;
  faceId?: string;
  error?: string;
}> {
  try {
    const selfieBytes = base64ToUint8Array(selfieBase64);
    const documentBytes = base64ToUint8Array(documentPhotoBase64);

    // 1. Detect faces in both images
    const selfieFaceResult = await detectFaces(selfieBytes, contextSpec);
    const documentFaceResult = await detectFaces(documentBytes, contextSpec);

    // Log quality issues for debugging but don't immediately fail
    if (!selfieFaceResult.isGoodQuality) {
      console.log('Selfie quality warning:', selfieFaceResult.error);
    }
    if (!documentFaceResult.isGoodQuality) {
      console.log('Document quality warning:', documentFaceResult.error);
    }

    // Only fail if we can't detect any faces at all
    if (selfieFaceResult.faces.length === 0 || documentFaceResult.faces.length === 0) {
      return {
        approved: false,
        confidence: 0,
        requiresManualReview: false,
        error: 'Could not detect faces in images. Please ensure face is clearly visible.'
      };
    }

    // If quality is poor but faces are detected, proceed but require manual review
    const hasQualityIssues = !selfieFaceResult.isGoodQuality || !documentFaceResult.isGoodQuality;

    // 2. Compare faces
    const comparisonResult = await compareFaces(selfieBytes, documentBytes, contextSpec);

    if (!comparisonResult.isMatch) {
      return {
        approved: false,
        confidence: comparisonResult.similarity,
        requiresManualReview: false,
        error: 'Face does not match document photo'
      };
    }

    const confidence = comparisonResult.similarity;

    // 3. Determine approval status - Auto-approve on reasonable confidence
    if (confidence >= CONFIDENCE_THRESHOLDS.AUTO_APPROVE) {
      // Auto-approve with good confidence regardless of minor quality issues
      const indexResult = await indexFace(selfieBytes, uin, 1, contextSpec);

      return {
        approved: true,
        confidence,
        requiresManualReview: false,
        faceId: indexResult.faceId,
      };
    } else if (confidence >= CONFIDENCE_THRESHOLDS.MANUAL_REVIEW) {
      // Auto-approve on reasonable confidence instead of manual review
      const indexResult = await indexFace(selfieBytes, uin, 1, contextSpec);

      return {
        approved: true,
        confidence,
        requiresManualReview: false,
        faceId: indexResult.faceId,
      };
    } else {
      // Only reject on very low confidence
      return {
        approved: false,
        confidence,
        requiresManualReview: false,
        error: `Face verification failed - confidence too low: ${confidence.toFixed(1)}%`
      };
    }
  } catch (error) {
    console.error('Error in SevisPass verification:', error);
    return {
      approved: false,
      confidence: 0,
      requiresManualReview: false,
      error: 'Verification process failed'
    };
  }
}

/**
 * Verify face for SevisPass login
 */
export async function verifySevisPassLogin(
  selfieBase64: string,
  expectedUin?: string
): Promise<{
  authenticated: boolean;
  uin?: string;
  confidence: number;
  error?: string;
}> {
  try {
    const selfieBytes = base64ToUint8Array(selfieBase64);

    // 1. Check face quality
    const faceResult = await detectFaces(selfieBytes);
    if (!faceResult.isGoodQuality) {
      return {
        authenticated: false,
        confidence: 0,
        error: 'Image quality is insufficient for verification'
      };
    }

    // 2. Search in collection
    const searchResult = await searchFaceInCollection(selfieBytes);

    if (!searchResult.success || !searchResult.bestMatch) {
      return {
        authenticated: false,
        confidence: 0,
        error: 'No matching identity found'
      };
    }

    const { uin, confidence } = searchResult.bestMatch;

    // 3. If UIN was provided, verify it matches
    if (expectedUin && uin !== expectedUin) {
      return {
        authenticated: false,
        confidence,
        error: 'Face does not match the provided UIN'
      };
    }

    // 4. Check if confidence meets login threshold
    if (confidence >= CONFIDENCE_THRESHOLDS.LOGIN) {
      return {
        authenticated: true,
        uin,
        confidence,
      };
    } else {
      return {
        authenticated: false,
        uin,
        confidence,
        error: 'Face verification confidence too low for authentication'
      };
    }
  } catch (error) {
    console.error('Error in SevisPass login verification:', error);
    return {
      authenticated: false,
      confidence: 0,
      error: 'Login verification failed'
    };
  }
}